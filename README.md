# Adversarial Robustness Benchmarks

Comparing adversarial defences has become a daunting task, with many defences reporting robustness improvements in spite of the fact that [they can easily be broken](https://arxiv.org/abs/2002.08347).


[This page](https://nullconvergence.github.io/adversarial-robustness-benchmarks/) gathers benchmarks for defences that either stood the test of time or proved effective.

The list is subject to continuous change and some defences may be removed as they are broken.
Contributions are welcomed.

We exclude certified defences because they can only provide certificates for the training data set.

Also, the neural network architecture may vary between different papers. 
The table is meant as an overview, to provide guidance for researchers and practitioners when navigating through defenses.
It should be taken with a grain of salt. 
The table's interpretation is in the eyes of the beholder.
